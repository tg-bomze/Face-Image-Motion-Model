# Face-Image-Motion-Model

![example](example.png)

**Check how it works on Google Colab:**
- Russian Language [![Colab](https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/tg-bomze/Face-Image-Motion-Model/blob/master/Face_Image_Motion_Model_(Photo_2_Video)_Rus.ipynb)
- English Language [![Colab](https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/tg-bomze/Face-Image-Motion-Model/blob/master/Face_Image_Motion_Model_(Photo_2_Video)_Eng.ipynb)

*If there are errors, you can find a solution [HERE](https://youtu.be/j9Yq6t4hUeA)*

**Based on:** [first-order-model](https://github.com/AliaksandrSiarohin/first-order-model)

**Special thanks for the help in creating Colabs I express to [JamesCullum](https://github.com/JamesCullum)**

The videos on the left show the driving videos. The first row on the right for each dataset shows the source videos. The bottom row contains the animated sequences with motion transferred from the driving video and object taken from the source image.
![teaser](https://github.com/AliaksandrSiarohin/first-order-model/raw/master/sup-mat/vox-teaser.gif)

**In addition, there are:**
- [VFIASC](https://github.com/sniklaus/sepconv-slomo)
- [ESRGAN](https://github.com/xinntao/ESRGAN)
- [EDVR](https://github.com/xinntao/EDVR) (new)

**Result Example:**

[![YouTube](youtube.png)](https://youtu.be/vmNJtEOLCIE)
