# Face-Image-Motion-Model
![example](example.png)

**Check how it works on Google Colab:**
- Russian Language [![Colab](https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/tg-bomze/Cloning-Facial-Expression/blob/master/Cloning_Facial_Expression_(Photo_2_Video)_Rus.ipynb)
- Bad English Translation [![Colab](https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/tg-bomze/Cloning-Facial-Expression/blob/master/Cloning_Facial_Expression_(Photo_2_Video)_Eng.ipynb)

**Based on:** [first-order-model](https://github.com/AliaksandrSiarohin/first-order-model)

The videos on the left show the driving videos. The first row on the right for each dataset shows the source videos. The bottom row contains the animated sequences with motion transferred from the driving video and object taken from the source image.
![teaser](https://github.com/AliaksandrSiarohin/first-order-model/raw/master/sup-mat/vox-teaser.gif)

**In addition, there are:**
- [VFIASC](https://github.com/sniklaus/sepconv-slomo)
- [ESRGAN](https://github.com/xinntao/ESRGAN)

**Result Example:**

[![YouTube](youtube.png)](https://youtu.be/vmNJtEOLCIE)
